// Importing express module
const express = require('express');
const app = express();
 
// Getting Request
app.get('/', (req, res) => {
 
    // Sending the response
    res.send('Hello World!')
    
    // Ending the response
    res.end()
})

app.post('/code', (req, res) => {
    res.json({
        "stderr": [],
        "compute": "// Generated by the Tensor Algebra Compiler (tensor-compiler.org)\n// /Users/kadhitha/purdue/workspace/my_taco/taco/build/bin/taco \"A(i,j) = B(i,k)* C(k,j)\" -f=A:dd:0,1 -f=B:dd:0,1 -f=C:dd:0,1 -print-nocolor -write-compute=Text-Files/compute.txt -write-assembly=Text-Files/assembly.txt -write-source=Text-Files/source.txt\n\nint compute(taco_tensor_t *A, taco_tensor_t *B, taco_tensor_t *C) {\n  int A1_dimension = (int)(A->dimensions[0]);\n  int A2_dimension = (int)(A->dimensions[1]);\n  double* restrict A_vals = (double*)(A->vals);\n  int B1_dimension = (int)(B->dimensions[0]);\n  int B2_dimension = (int)(B->dimensions[1]);\n  double* restrict B_vals = (double*)(B->vals);\n  int C1_dimension = (int)(C->dimensions[0]);\n  int C2_dimension = (int)(C->dimensions[1]);\n  double* restrict C_vals = (double*)(C->vals);\n\n  #pragma omp parallel for schedule(static)\n  for (int32_t pA = 0; pA < (A1_dimension * A2_dimension); pA++) {\n    A_vals[pA] = 0.0;\n  }\n\n  #pragma omp parallel for schedule(runtime)\n  for (int32_t i = 0; i < B1_dimension; i++) {\n    for (int32_t k = 0; k < C1_dimension; k++) {\n      int32_t kB = i * B2_dimension + k;\n      for (int32_t j = 0; j < C2_dimension; j++) {\n        int32_t jA = i * A2_dimension + j;\n        int32_t jC = k * C2_dimension + j;\n        A_vals[jA] = A_vals[jA] + B_vals[kB] * C_vals[jC];\n      }\n    }\n  }\n  return 0;\n}\n",
        "assembly": "// Generated by the Tensor Algebra Compiler (tensor-compiler.org)\n// /Users/kadhitha/purdue/workspace/my_taco/taco/build/bin/taco \"A(i,j) = B(i,k)* C(k,j)\" -f=A:dd:0,1 -f=B:dd:0,1 -f=C:dd:0,1 -print-nocolor -write-compute=Text-Files/compute.txt -write-assembly=Text-Files/assembly.txt -write-source=Text-Files/source.txt\n\nint assemble(taco_tensor_t *A, taco_tensor_t *B, taco_tensor_t *C) {\n  int A1_dimension = (int)(A->dimensions[0]);\n  int A2_dimension = (int)(A->dimensions[1]);\n  double* restrict A_vals = (double*)(A->vals);\n\n  A_vals = (double*)malloc(sizeof(double) * (A1_dimension * A2_dimension));\n\n  A->vals = (uint8_t*)A_vals;\n  return 0;\n}\n",
        "source": "// Generated by the Tensor Algebra Compiler (tensor-compiler.org)\n// /Users/kadhitha/purdue/workspace/my_taco/taco/build/bin/taco \"A(i,j) = B(i,k)* C(k,j)\" -f=A:dd:0,1 -f=B:dd:0,1 -f=C:dd:0,1 -print-nocolor -write-compute=Text-Files/compute.txt -write-assembly=Text-Files/assembly.txt -write-source=Text-Files/source.txt\n#ifndef TACO_C_HEADERS\n#define TACO_C_HEADERS\n#include <stdio.h>\n#include <stdlib.h>\n#include <stdint.h>\n#include <stdbool.h>\n#include <math.h>\n#include <complex.h>\n#include <string.h>\n#if _OPENMP\n#include <omp.h>\n#endif\n#define TACO_MIN(_a,_b) ((_a) < (_b) ? (_a) : (_b))\n#define TACO_MAX(_a,_b) ((_a) > (_b) ? (_a) : (_b))\n#define TACO_DEREF(_a) (((___context___*)(*__ctx__))->_a)\n#ifndef TACO_TENSOR_T_DEFINED\n#define TACO_TENSOR_T_DEFINED\ntypedef enum { taco_mode_dense, taco_mode_sparse } taco_mode_t;\ntypedef struct {\n  int32_t      order;         // tensor order (number of modes)\n  int32_t*     dimensions;    // tensor dimensions\n  int32_t      csize;         // component size\n  int32_t*     mode_ordering; // mode storage ordering\n  taco_mode_t* mode_types;    // mode storage types\n  uint8_t***   indices;       // tensor index data (per mode)\n  uint8_t*     vals;          // tensor values\n  int32_t      vals_size;     // values array size\n} taco_tensor_t;\n#endif\n#if !_OPENMP\nint omp_get_thread_num() { return 0; }\nint omp_get_max_threads() { return 1; }\n#endif\nint cmp(const void *a, const void *b) {\n  return *((const int*)a) - *((const int*)b);\n}\nint taco_binarySearchAfter(int *array, int arrayStart, int arrayEnd, int target) {\n  if (array[arrayStart] >= target) {\n    return arrayStart;\n  }\n  int lowerBound = arrayStart; // always < target\n  int upperBound = arrayEnd; // always >= target\n  while (upperBound - lowerBound > 1) {\n    int mid = (upperBound + lowerBound) / 2;\n    int midValue = array[mid];\n    if (midValue < target) {\n      lowerBound = mid;\n    }\n    else if (midValue > target) {\n      upperBound = mid;\n    }\n    else {\n      return mid;\n    }\n  }\n  return upperBound;\n}\nint taco_binarySearchBefore(int *array, int arrayStart, int arrayEnd, int target) {\n  if (array[arrayEnd] <= target) {\n    return arrayEnd;\n  }\n  int lowerBound = arrayStart; // always <= target\n  int upperBound = arrayEnd; // always > target\n  while (upperBound - lowerBound > 1) {\n    int mid = (upperBound + lowerBound) / 2;\n    int midValue = array[mid];\n    if (midValue < target) {\n      lowerBound = mid;\n    }\n    else if (midValue > target) {\n      upperBound = mid;\n    }\n    else {\n      return mid;\n    }\n  }\n  return lowerBound;\n}\ntaco_tensor_t* init_taco_tensor_t(int32_t order, int32_t csize,\n                                  int32_t* dimensions, int32_t* mode_ordering,\n                                  taco_mode_t* mode_types) {\n  taco_tensor_t* t = (taco_tensor_t *) malloc(sizeof(taco_tensor_t));\n  t->order         = order;\n  t->dimensions    = (int32_t *) malloc(order * sizeof(int32_t));\n  t->mode_ordering = (int32_t *) malloc(order * sizeof(int32_t));\n  t->mode_types    = (taco_mode_t *) malloc(order * sizeof(taco_mode_t));\n  t->indices       = (uint8_t ***) malloc(order * sizeof(uint8_t***));\n  t->csize         = csize;\n  for (int32_t i = 0; i < order; i++) {\n    t->dimensions[i]    = dimensions[i];\n    t->mode_ordering[i] = mode_ordering[i];\n    t->mode_types[i]    = mode_types[i];\n    switch (t->mode_types[i]) {\n      case taco_mode_dense:\n        t->indices[i] = (uint8_t **) malloc(1 * sizeof(uint8_t **));\n        break;\n      case taco_mode_sparse:\n        t->indices[i] = (uint8_t **) malloc(2 * sizeof(uint8_t **));\n        break;\n    }\n  }\n  return t;\n}\nvoid deinit_taco_tensor_t(taco_tensor_t* t) {\n  for (int i = 0; i < t->order; i++) {\n    free(t->indices[i]);\n  }\n  free(t->indices);\n  free(t->dimensions);\n  free(t->mode_ordering);\n  free(t->mode_types);\n  free(t);\n}\n#endif\n\nint compute(taco_tensor_t *A, taco_tensor_t *B, taco_tensor_t *C) {\n  int A1_dimension = (int)(A->dimensions[0]);\n  int A2_dimension = (int)(A->dimensions[1]);\n  double* restrict A_vals = (double*)(A->vals);\n  int B1_dimension = (int)(B->dimensions[0]);\n  int B2_dimension = (int)(B->dimensions[1]);\n  double* restrict B_vals = (double*)(B->vals);\n  int C1_dimension = (int)(C->dimensions[0]);\n  int C2_dimension = (int)(C->dimensions[1]);\n  double* restrict C_vals = (double*)(C->vals);\n\n  #pragma omp parallel for schedule(static)\n  for (int32_t pA = 0; pA < (A1_dimension * A2_dimension); pA++) {\n    A_vals[pA] = 0.0;\n  }\n\n  #pragma omp parallel for schedule(runtime)\n  for (int32_t i = 0; i < B1_dimension; i++) {\n    for (int32_t k = 0; k < C1_dimension; k++) {\n      int32_t kB = i * B2_dimension + k;\n      for (int32_t j = 0; j < C2_dimension; j++) {\n        int32_t jA = i * A2_dimension + j;\n        int32_t jC = k * C2_dimension + j;\n        A_vals[jA] = A_vals[jA] + B_vals[kB] * C_vals[jC];\n      }\n    }\n  }\n  return 0;\n}\n\nint assemble(taco_tensor_t *A, taco_tensor_t *B, taco_tensor_t *C) {\n  int A1_dimension = (int)(A->dimensions[0]);\n  int A2_dimension = (int)(A->dimensions[1]);\n  double* restrict A_vals = (double*)(A->vals);\n\n  A_vals = (double*)malloc(sizeof(double) * (A1_dimension * A2_dimension));\n\n  A->vals = (uint8_t*)A_vals;\n  return 0;\n}\n\nint evaluate(taco_tensor_t *A, taco_tensor_t *B, taco_tensor_t *C) {\n  int A1_dimension = (int)(A->dimensions[0]);\n  int A2_dimension = (int)(A->dimensions[1]);\n  double* restrict A_vals = (double*)(A->vals);\n  int B1_dimension = (int)(B->dimensions[0]);\n  int B2_dimension = (int)(B->dimensions[1]);\n  double* restrict B_vals = (double*)(B->vals);\n  int C1_dimension = (int)(C->dimensions[0]);\n  int C2_dimension = (int)(C->dimensions[1]);\n  double* restrict C_vals = (double*)(C->vals);\n\n  int32_t A_capacity = A1_dimension * A2_dimension;\n  A_vals = (double*)malloc(sizeof(double) * A_capacity);\n\n  #pragma omp parallel for schedule(static)\n  for (int32_t pA = 0; pA < A_capacity; pA++) {\n    A_vals[pA] = 0.0;\n  }\n\n  #pragma omp parallel for schedule(runtime)\n  for (int32_t i = 0; i < B1_dimension; i++) {\n    for (int32_t k = 0; k < C1_dimension; k++) {\n      int32_t kB = i * B2_dimension + k;\n      for (int32_t j = 0; j < C2_dimension; j++) {\n        int32_t jA = i * A2_dimension + j;\n        int32_t jC = k * C2_dimension + j;\n        A_vals[jA] = A_vals[jA] + B_vals[kB] * C_vals[jC];\n      }\n    }\n  }\n\n  A->vals = (uint8_t*)A_vals;\n  return 0;\n}\n\n/*\n * The `pack` functions convert coordinate and value arrays in COO format,\n * with nonzeros sorted lexicographically by their coordinates, to the\n * specified input format.\n *\n * The `unpack` function converts the specified output format to coordinate\n * and value arrays in COO format.\n *\n * For both, the `_COO_pos` arrays contain two elements, where the first is 0\n * and the second is the number of nonzeros in the tensor.\n */\n\nint pack_B(taco_tensor_t *B, int* B_COO1_pos, int* B_COO1_crd, int* B_COO2_crd, double* B_COO_vals) {\n  int B1_dimension = (int)(B->dimensions[0]);\n  int B2_dimension = (int)(B->dimensions[1]);\n  double* restrict B_vals = (double*)(B->vals);\n\n  int32_t B_capacity = B1_dimension * B2_dimension;\n  B_vals = (double*)malloc(sizeof(double) * B_capacity);\n\n  #pragma omp parallel for schedule(static)\n  for (int32_t pB = 0; pB < B_capacity; pB++) {\n    B_vals[pB] = 0.0;\n  }\n\n  int32_t iB_COO = B_COO1_pos[0];\n  int32_t pB_COO1_end = B_COO1_pos[1];\n\n  while (iB_COO < pB_COO1_end) {\n    int32_t i = B_COO1_crd[iB_COO];\n    int32_t B_COO1_segend = iB_COO + 1;\n    while (B_COO1_segend < pB_COO1_end && B_COO1_crd[B_COO1_segend] == i) {\n      B_COO1_segend++;\n    }\n    int32_t kB_COO = iB_COO;\n\n    while (kB_COO < B_COO1_segend) {\n      int32_t k = B_COO2_crd[kB_COO];\n      double B_COO_val = B_COO_vals[kB_COO];\n      kB_COO++;\n      while (kB_COO < B_COO1_segend && B_COO2_crd[kB_COO] == k) {\n        B_COO_val += B_COO_vals[kB_COO];\n        kB_COO++;\n      }\n      int32_t kB = i * B2_dimension + k;\n      B_vals[kB] = B_COO_val;\n    }\n    iB_COO = B_COO1_segend;\n  }\n\n  B->vals = (uint8_t*)B_vals;\n  return 0;\n}\n\nint pack_C(taco_tensor_t *C, int* C_COO1_pos, int* C_COO1_crd, int* C_COO2_crd, double* C_COO_vals) {\n  int C1_dimension = (int)(C->dimensions[0]);\n  int C2_dimension = (int)(C->dimensions[1]);\n  double* restrict C_vals = (double*)(C->vals);\n\n  int32_t C_capacity = C1_dimension * C2_dimension;\n  C_vals = (double*)malloc(sizeof(double) * C_capacity);\n\n  #pragma omp parallel for schedule(static)\n  for (int32_t pC = 0; pC < C_capacity; pC++) {\n    C_vals[pC] = 0.0;\n  }\n\n  int32_t kC_COO = C_COO1_pos[0];\n  int32_t pC_COO1_end = C_COO1_pos[1];\n\n  while (kC_COO < pC_COO1_end) {\n    int32_t k = C_COO1_crd[kC_COO];\n    int32_t C_COO1_segend = kC_COO + 1;\n    while (C_COO1_segend < pC_COO1_end && C_COO1_crd[C_COO1_segend] == k) {\n      C_COO1_segend++;\n    }\n    int32_t jC_COO = kC_COO;\n\n    while (jC_COO < C_COO1_segend) {\n      int32_t j = C_COO2_crd[jC_COO];\n      double C_COO_val = C_COO_vals[jC_COO];\n      jC_COO++;\n      while (jC_COO < C_COO1_segend && C_COO2_crd[jC_COO] == j) {\n        C_COO_val += C_COO_vals[jC_COO];\n        jC_COO++;\n      }\n      int32_t jC = k * C2_dimension + j;\n      C_vals[jC] = C_COO_val;\n    }\n    kC_COO = C_COO1_segend;\n  }\n\n  C->vals = (uint8_t*)C_vals;\n  return 0;\n}\n\nint unpack(int** A_COO1_pos_ptr, int** A_COO1_crd_ptr, int** A_COO2_crd_ptr, double** A_COO_vals_ptr, taco_tensor_t *A) {\n  int* A_COO1_pos;\n  int* A_COO1_crd;\n  int* A_COO2_crd;\n  double* A_COO_vals;\n  int A1_dimension = (int)(A->dimensions[0]);\n  int A2_dimension = (int)(A->dimensions[1]);\n  double* restrict A_vals = (double*)(A->vals);\n\n  A_COO1_pos = (int32_t*)malloc(sizeof(int32_t) * 2);\n  A_COO1_pos[0] = 0;\n  int32_t A_COO1_crd_size = 1048576;\n  A_COO1_crd = (int32_t*)malloc(sizeof(int32_t) * A_COO1_crd_size);\n  int32_t A_COO2_crd_size = 1048576;\n  A_COO2_crd = (int32_t*)malloc(sizeof(int32_t) * A_COO2_crd_size);\n  int32_t jA_COO = 0;\n  int32_t A_COO_capacity = 1048576;\n  A_COO_vals = (double*)malloc(sizeof(double) * A_COO_capacity);\n\n\n  for (int32_t i = 0; i < A1_dimension; i++) {\n    for (int32_t j = 0; j < A2_dimension; j++) {\n      if (A_COO_capacity <= jA_COO) {\n        A_COO_vals = (double*)realloc(A_COO_vals, sizeof(double) * (A_COO_capacity * 2));\n        A_COO_capacity *= 2;\n      }\n      int32_t jA = i * A2_dimension + j;\n      A_COO_vals[jA_COO] = A_vals[jA];\n      if (A_COO2_crd_size <= jA_COO) {\n        int32_t A_COO2_crd_new_size = TACO_MAX(A_COO2_crd_size * 2,(jA_COO + 1));\n        A_COO2_crd = (int32_t*)realloc(A_COO2_crd, sizeof(int32_t) * A_COO2_crd_new_size);\n        A_COO2_crd_size = A_COO2_crd_new_size;\n      }\n      A_COO2_crd[jA_COO] = j;\n      if (A_COO1_crd_size <= jA_COO) {\n        A_COO1_crd = (int32_t*)realloc(A_COO1_crd, sizeof(int32_t) * (A_COO1_crd_size * 2));\n        A_COO1_crd_size *= 2;\n      }\n      A_COO1_crd[jA_COO] = i;\n      jA_COO++;\n    }\n  }\n\n  A_COO1_pos[1] = jA_COO;\n\n  *A_COO1_pos_ptr = A_COO1_pos;\n  *A_COO1_crd_ptr = A_COO1_crd;\n  *A_COO2_crd_ptr = A_COO2_crd;\n  *A_COO_vals_ptr = A_COO_vals;\n  return 0;\n}\n",
        "error": ""
    })
    res.end()
})
 
// Establishing the port
const PORT = process.env.PORT || 5005;
 
// Executing the server on given port number
app.listen(PORT, console.log(
  `Server started on port ${PORT}`));